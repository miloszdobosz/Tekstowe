{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementacje algorytmów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import PriorityQueue\n",
    "from bitarray import bitarray\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Statyczny algorytm Huffmana:\n",
    "\n",
    "Skompresowany tekst przechowywany jest w pliku w trzech częściach oddzielonych znakiem kowej linii:\n",
    "- tekstowego nagłówka\n",
    "- długości paddingu zakodowanego tekstu\n",
    "- binarnego zakodowanego tekstu.\n",
    "\n",
    "#### Kompresja:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_tree(text: str) -> tuple:\n",
    "    \"\"\"Tworzy z tekstu drzewo zapisane jako krotkę\"\"\"\n",
    "    \n",
    "    # Liczba wystąpień poszczególnych liter w tekście\n",
    "    counts = defaultdict(lambda: 0)\n",
    "    for letter in text:\n",
    "        counts[letter] += 1\n",
    "\n",
    "    # Kolejka priorytetowa według liczby wystąpień rosnąco\n",
    "    # Bez id ma problem z porównywaniem przy tym samym count\n",
    "    Q = PriorityQueue()\n",
    "    for unique_id, (letter, count) in enumerate(counts.items()):\n",
    "        Q.put((count, unique_id, letter))\n",
    "\n",
    "    count_a, id_a, subtree_a = Q.get()\n",
    "\n",
    "    while not Q.empty():\n",
    "        count_b, _, subtree_b = Q.get()\n",
    "        Q.put((count_a + count_b, id_a, (subtree_a, subtree_b)))\n",
    "        # Tutaj kolejka nie będzie pusta\n",
    "        count_a, id_a, subtree_a = Q.get()\n",
    "\n",
    "    return subtree_a\n",
    "\n",
    "\n",
    "def static_codes(tree: tuple) -> dict:\n",
    "    \"\"\"Wylicza kody na podstawie drzewa\"\"\"\n",
    "    codes = {}\n",
    "\n",
    "    def encode(node, code):\n",
    "        if isinstance(node, str):\n",
    "            codes[node] = bitarray(code)\n",
    "            return\n",
    "\n",
    "        a, b = node\n",
    "        encode(a, code + \"0\")\n",
    "        encode(b, code + \"1\")\n",
    "\n",
    "    encode(tree, \"\")\n",
    "    return codes\n",
    "\n",
    "\n",
    "def static_encode(text: str, codes: dict) -> bitarray:\n",
    "    \"\"\"Zamienia otrzymany tekst w dane binarnie zakodowane\"\"\"\n",
    "\n",
    "    compressed = bitarray()\n",
    "    # To na tyle prosta operacja że pozwalam sobie użyć biblioteki\n",
    "    compressed.encode(codes, text)\n",
    "    return compressed\n",
    "\n",
    "\n",
    "def static_compress(text: str, path: str = \"file\") -> None:\n",
    "    \"\"\"Kompresuje otrzymany tekst do pliku\"\"\"\n",
    "\n",
    "    tree = static_tree(text)\n",
    "    compressed = static_encode(text, codes=static_codes(tree))\n",
    "\n",
    "    with open(path, \"wb\") as file:\n",
    "        # drzewo Huffmana oraz długość paddingu\n",
    "        file.write(bytes(repr(tree) + \"\\n\" + str(compressed.fill()) + \"\\n\", \"utf\"))\n",
    "        file.write(compressed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dekompresja:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_decompress(path=\"file\", verbose=False):\n",
    "    with open(path, \"rb\") as file:\n",
    "        tree = eval(file.readline())\n",
    "        if verbose:\n",
    "            print(\"Drzewo: \", tree)\n",
    "        padding = int(file.readline())\n",
    "        compressed = bitarray()\n",
    "        compressed.fromfile(file)\n",
    "        del compressed[-padding:]\n",
    "\n",
    "    letters = []\n",
    "    node = tree\n",
    "    for i in range(len(compressed)):\n",
    "        node = node[compressed[i]]\n",
    "\n",
    "        if isinstance(node, str):\n",
    "            letters.append(node)\n",
    "            node = tree\n",
    "    \n",
    "    return \"\".join(letters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_compress(\"dziala heheheheee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dziala heheheheee'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_decompress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"(((' ', ('d', 'z')), (('i', 'l'), 'a')), ('h', 'e'))\\n3\\n#F\\xac]\\xdd\\xf8\"\n"
     ]
    }
   ],
   "source": [
    "with open(\"file\", \"rb\") as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pomiary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randbytes\n",
    "with open(\"random\", \"wb\") as file:\n",
    "    file.write(randbytes(1_000_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File:  bfq-iosched.c\n",
      "\tFile size:  1000 B\n",
      "\tRatio:  1.045\n",
      "\tCompression time:  0.0016186237335205078 s.\n",
      "\tDecompression time:  0.002304553985595703 s.\n",
      "\n",
      "File:  bfq-iosched.c\n",
      "\tFile size:  10000 B\n",
      "\tRatio:  0.6975\n",
      "\tCompression time:  0.004084110260009766 s.\n",
      "\tDecompression time:  0.011548042297363281 s.\n",
      "\n",
      "File:  bfq-iosched.c\n",
      "\tFile size:  100000 B\n",
      "\tRatio:  0.62351\n",
      "\tCompression time:  0.021536827087402344 s.\n",
      "\tDecompression time:  0.0936117172241211 s.\n",
      "\n",
      "File:  bfq-iosched.c\n",
      "\tFile size:  1000000 B\n",
      "\tRatio:  0.627429961321222\n",
      "\tCompression time:  0.029646873474121094 s.\n",
      "\tDecompression time:  0.1361222267150879 s.\n",
      "\n",
      "File:  pg34073.txt\n",
      "\tFile size:  1000 B\n",
      "\tRatio:  1.134\n",
      "\tCompression time:  0.0011341571807861328 s.\n",
      "\tDecompression time:  0.0014781951904296875 s.\n",
      "\n",
      "File:  pg34073.txt\n",
      "\tFile size:  10000 B\n",
      "\tRatio:  0.6832\n",
      "\tCompression time:  0.004385709762573242 s.\n",
      "\tDecompression time:  0.009641647338867188 s.\n",
      "\n",
      "File:  pg34073.txt\n",
      "\tFile size:  100000 B\n",
      "\tRatio:  0.60839\n",
      "\tCompression time:  0.01846766471862793 s.\n",
      "\tDecompression time:  0.0917060375213623 s.\n",
      "\n",
      "File:  pg34073.txt\n",
      "\tFile size:  1000000 B\n",
      "\tRatio:  0.5946111563892175\n",
      "\tCompression time:  0.11336016654968262 s.\n",
      "\tDecompression time:  0.559434175491333 s.\n",
      "\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb2 in position 1: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21881/1875167926.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mstatic_compress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.9/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb2 in position 1: invalid start byte"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "names = [\"bfq-iosched.c\", \"pg34073.txt\", \"random\"]\n",
    "sizes = [1_000, 10_000, 100_000, 1_000_000]\n",
    "\n",
    "for name in names:\n",
    "    with open(name, \"r\") as file:\n",
    "        for size in sizes:\n",
    "            text = file.read(size)\n",
    "            start = time.time()\n",
    "            static_compress(text)\n",
    "            compression_time = time.time()\n",
    "            static_decompress()\n",
    "            decompression_time = time.time()\n",
    "            with open(\"file\", \"rb\") as compressed:\n",
    "                compressed = compressed.read()\n",
    "            print(\"File: \", name)\n",
    "            print(\"\\tFile size: \", size, \"B\")\n",
    "            print(\"\\tRatio: \", len(compressed) / len(text))\n",
    "            print(\"\\tCompression time: \", compression_time - start, \"s.\")\n",
    "            print(\"\\tDecompression time: \", decompression_time - compression_time, \"s.\")\n",
    "            print()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dynamiczny algorytm Huffmana:\n",
    "\n",
    "Spędziłem nad tym paręnaście godzin i niestety nie działa (choć coś tam się koduje w pliku).\n",
    "\n",
    "Plik jest przechowywany jako ciąg zakodowanych binarnie danych. Gdy pojawia się kod którego dekoder nie zna następnym bajtem jest litera którą on oznacza. Dekoder na bieżąco modyfikuje drzewo w ten sam sposób co enkoder, zmieniając znaczenia kodów.\n",
    "\n",
    "#### Kompresja:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, letter=\"\", weight=1, parent=None, child=[None, None]):\n",
    "        self.weight = weight\n",
    "        self.letter = letter\n",
    "        self.parent = parent\n",
    "        self.child = child\n",
    "\n",
    "    def get_code(self):\n",
    "        code = \"\"\n",
    "        while self.parent:\n",
    "            if self.which_child() == 0:\n",
    "                code = \"0\" + code\n",
    "            else:\n",
    "                code = \"1\" + code\n",
    "            self = self.parent\n",
    "        return code\n",
    "\n",
    "    def update_weight(self, value=1):\n",
    "        self.weight += value\n",
    "\n",
    "        if self.parent:\n",
    "            self.parent.update_weight(value)\n",
    "\n",
    "        possible_swap = self.find_swap()\n",
    "        if possible_swap:\n",
    "            self.swap(possible_swap)\n",
    "\n",
    "    def swap(self, other):\n",
    "        s = self.which_child()\n",
    "        o = other.which_child()\n",
    "\n",
    "        # Podmiana wag\n",
    "        self.parent.update_weight(other.weight - self.weight)\n",
    "        other.parent.update_weight(self.weight - other.weight)\n",
    "\n",
    "        # Podmiana wskażników rodziców na dzieci\n",
    "        self.parent.children[s], other.parent.children[o] = (\n",
    "            other.parent.children[o],\n",
    "            self.parent.children[s],\n",
    "        )\n",
    "        # Podmiana wskaźników dzieci na rodziców\n",
    "        self.parent, other.parent = other.parent, self.parent\n",
    "\n",
    "    def which_child(self):\n",
    "        if self.parent:\n",
    "            return 0 if self is self.parent.child[0] else 1\n",
    "\n",
    "    def find_swap(self):\n",
    "        previous = self\n",
    "        current = self.find_next()\n",
    "\n",
    "        # W razie gdyby wiele węzłów miałą tę samą wagę\n",
    "        while current and current.weight < self.weight:\n",
    "            previous = current\n",
    "            current = current.find_next()\n",
    "\n",
    "        # Jeśli self nie jest największy na swoim poziomie\n",
    "        if current and previous is not self:\n",
    "            return previous\n",
    "\n",
    "        current = self.find_next_above()\n",
    "        while current and current.weight < self.weight:\n",
    "            previous = current\n",
    "            current = current.find_next()\n",
    "\n",
    "    def find_next(self, level=0):\n",
    "        \"\"\"Zwraca następny węzeł na tym samym poziomie lub None jeśli self jest ostatnim\"\"\"\n",
    "\n",
    "        current = self\n",
    "\n",
    "        if not current.parent:\n",
    "            return None\n",
    "        \n",
    "        # Wychodzimy po większych dzieciach dopóki nie\n",
    "        # (jesteśmy mniejszym i istnieje większe)\n",
    "        while current.which_child() == 1 or not current.parent.child[1]:\n",
    "            current = current.parent\n",
    "            level += 1\n",
    "            \n",
    "            # Self jest największy na swoim poziomie\n",
    "            if not current.parent:\n",
    "                return None\n",
    "\n",
    "        # Zmieniamy na większe dziecko kiedy jesteśmy mniejszym\n",
    "        current = current.parent.child[1]\n",
    "\n",
    "        # Schodzimy na odpowiedni poziom po najmniejszych dzieciach\n",
    "        while level > 0:\n",
    "            if current.child[0]:\n",
    "                current = current.child[0]\n",
    "                level -= 1\n",
    "            elif current.child[1]:\n",
    "                current = current.child[1]\n",
    "                level -= 1\n",
    "            else:\n",
    "                # Jeśli nie da się dojść na odpowiedni poziom to szukamy następnej ścieżki\n",
    "                return current.find_next(level)\n",
    "\n",
    "        return current\n",
    "\n",
    "    def find_next_above(self):\n",
    "        \"\"\"Zwraca pierwszy węzeł na poziomie wyżej\"\"\"\n",
    "\n",
    "        current = self\n",
    "        level = 0\n",
    "\n",
    "        # Wychodzimy do korzenia\n",
    "        while current.parent:\n",
    "            current = current.parent\n",
    "            level += 1\n",
    "\n",
    "        # Schodzimy po mniejszych dzieciach\n",
    "        while level > 1:\n",
    "            if current.child[0]:\n",
    "                current = current.child[0]\n",
    "                level -= 1\n",
    "            elif current.child[1]:\n",
    "                current = current.child[1]\n",
    "                level -= 1\n",
    "            else:\n",
    "                current = current.find_next(level)\n",
    "\n",
    "        return current\n",
    "    \n",
    "    def __repr__(self):\n",
    "        child_0 = str(self.child[0]) if self.child[0] else \"\"\n",
    "        child_1 = str(self.child[1]) if self.child[1] else \"\"\n",
    "        letter = str(self.letter) + \" \" if self.letter else \"\"\n",
    "        return f\"[{letter}{str(self.weight)}]( {child_0} {child_1} )\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dekompresja:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_compress(text, path=\"dynamic\"):\n",
    "    nyt = Node(\"NYT\", 0)\n",
    "    nodes = {None: nyt}\n",
    "    tree = nyt\n",
    "    \n",
    "    with open(path, \"wb\") as file:\n",
    "        for letter in text:\n",
    "            if letter in nodes:\n",
    "                file.write(bytes(nodes[letter].get_code() + \" \", \"utf\"))\n",
    "                nodes[letter].update_weight(1)\n",
    "\n",
    "            else:\n",
    "                letter_node = Node(letter)\n",
    "                nodes[letter] = letter_node\n",
    "                # print(letter_node)\n",
    "\n",
    "                new_node = Node(child=[nyt, letter_node])\n",
    "                letter_node.parent = new_node\n",
    "                \n",
    "                if nyt.parent:\n",
    "                    nyt.parent.child[0] = new_node\n",
    "                else:\n",
    "                    tree = new_node\n",
    "                nyt.parent, new_node.parent = new_node, nyt.parent\n",
    "\n",
    "                file.write(bytes(letter_node.get_code() + \" \", \"utf\"))\n",
    "                file.write(bytes(letter + \" \", \"utf\"))\n",
    "\n",
    "            print(tree)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dekodowanie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_decompress(path=\"dynamic\"):\n",
    "    letters = []\n",
    "\n",
    "    nyt = Node(\"NYT\", 0)\n",
    "    nodes = {None: nyt}\n",
    "    tree = nyt\n",
    "    node = tree\n",
    "    \n",
    "    with open(path, \"rb\") as file:\n",
    "        compressed = bitarray()\n",
    "        compressed.fromfile(file)\n",
    "\n",
    "        for i in range(len(compressed)):\n",
    "            print(node)\n",
    "            if node.child[compressed[i]]:\n",
    "                node = node.child[compressed[i]]\n",
    "                if node.letter:\n",
    "                    letters.append(node.letter)\n",
    "                    node.update_weight(1)\n",
    "                    nodes[letter].update_weight(1)\n",
    "                    node = tree\n",
    "\n",
    "            else:\n",
    "                node.child[compressed[i]] = Node(str(compressed[i+1:i+9].tobytes()))\n",
    "                i += 9\n",
    "                node.child[0] = Node()\n",
    "                node = tree\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # letter_node = Node(letter)\n",
    "                # nodes[letter] = letter_node\n",
    "                # # print(letter_node)\n",
    "\n",
    "                # new_node = Node(child=[nyt, letter_node])\n",
    "                # letter_node.parent = new_node\n",
    "                \n",
    "                # if nyt.parent:\n",
    "                #     nyt.parent.child[0] = new_node\n",
    "                # else:\n",
    "                #     tree = new_node\n",
    "                # nyt.parent, new_node.parent = new_node, nyt.parent\n",
    "\n",
    "                # file.write(bytes(letter_node.get_code() + \" \", \"utf\"))\n",
    "                # file.write(bytes(letter + \" \", \"utf\"))\n",
    "\n",
    "            # print(tree)\n",
    "    \n",
    "    return \"\".join(letters)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Node' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21881/229160866.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdynamic_compress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ccciekawe\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_21881/927920007.py\u001b[0m in \u001b[0;36mdynamic_compress\u001b[0;34m(text, path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdynamic_compress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dynamic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnyt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NYT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnyt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnyt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Node' is not defined"
     ]
    }
   ],
   "source": [
    "dynamic_compress(\"ccciekawe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Node' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21881/361383390.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdynamic_decompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_21881/1722082007.py\u001b[0m in \u001b[0;36mdynamic_decompress\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mletters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnyt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NYT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnyt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnyt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Node' is not defined"
     ]
    }
   ],
   "source": [
    "dynamic_decompress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'1 c 1 1 01 i 001 e 0001 k 00001 a 000001 w 001 '\n"
     ]
    }
   ],
   "source": [
    "with open(\"dynamic\", \"rb\") as file:\n",
    "    print(file.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Mar  1 2023, 18:23:06) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "586ad1ed5c97141e2437e681efbf1ec0adcd17d830cf5af2ca3d2819e743e158"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
